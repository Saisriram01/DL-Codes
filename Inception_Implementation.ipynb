{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Nf0oMbUv_Mvw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BeforeModules(nn.Module):\n",
        "  def __init__(self,in_channels):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "\n",
        "    self.conv1 = nn.Conv2d(self.in_channels, 64, kernel_size  = 7, stride = 2,padding = 3 ,bias = False)\n",
        "    self.bn1 = nn.BatchNorm2d( num_features = 64)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2 ,padding = 1)\n",
        "    self.conv2 = nn.Conv2d(64, 64, kernel_size  = 1, stride = 1, bias = False)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(64, 192, kernel_size=3 ,stride = 1, padding = 1,bias = False)\n",
        "    self.bn2 = nn.BatchNorm2d( num_features = 192)\n",
        "\n",
        "    print(\"Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\")\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.maxpool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "B1ab0ReR_k5t"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Aux_Classifier(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes = 1000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.avgpool_aux = nn.AvgPool2d(kernel_size = 5, stride=3)\n",
        "    self.conv_aux = nn.Conv2d(in_channels = self.in_channels, out_channels=128, kernel_size=1, stride=1, bias = False)\n",
        "    self.bn = nn.BatchNorm2d(num_features=self.conv_aux.out_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc_aux = nn.Linear(in_features = 2048, out_features = 1024)#4*4*128\n",
        "    self.bn_fc_aux = nn.BatchNorm1d(num_features=self.fc_aux.out_features)\n",
        "    self.dropout_aux = nn.Dropout(p=0.7)\n",
        "    self.classifier_aux = nn.Linear(in_features=self.fc_aux.out_features, out_features=num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.avgpool_aux(x)\n",
        "    x = self.conv_aux(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc_aux(x)\n",
        "    x = self.bn_fc_aux(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout_aux(x)\n",
        "    out = self.classifier_aux(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "ko_pEdCTlGxj"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inc_Module(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels_list):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    # self.conv1x1_l1--> conv layer of 1x1 size, in picture 1st layer from left\n",
        "    self.conv1x1_l1 = nn.Conv2d( self.in_channels, out_channels_list[0] , stride = 1, kernel_size = 1, bias= False )\n",
        "    self.convreduce3x3 = nn.Conv2d( self.in_channels, out_channels_list[1] , stride = 1, kernel_size = 1, bias= False )\n",
        "    self.convreduce5x5 = nn.Conv2d( self.in_channels, out_channels_list[3] , stride = 1, kernel_size = 1,bias= False )\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 1,padding = 1)\n",
        "\n",
        "    self.conv3x3 = nn.Conv2d(out_channels_list[1], out_channels_list[2],kernel_size = 3, padding = 1, stride = 1, bias = False)\n",
        "    self.conv5x5 = nn.Conv2d(out_channels_list[3], out_channels_list[4],kernel_size = 5, padding = 2, stride = 1, bias = False)\n",
        "    self.conv1x1_l4 = nn.Conv2d( self.in_channels, out_channels_list[5] , kernel_size = 1, stride = 1, bias= False )\n",
        "\n",
        "    self.out_channels = sum(out_channels_list) - out_channels_list[1] - out_channels_list[3]\n",
        "\n",
        "    print(\"Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\")\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # making 4 copies of x and applying respective operations in x1, x2, x3, x4\n",
        "\n",
        "    x1 = self.conv1x1_l1(x)\n",
        "    x1 = self.relu(x1)\n",
        "\n",
        "    x2 = self.convreduce3x3(x)\n",
        "    x2 = self.relu(x2)\n",
        "    x2 = self.conv3x3(x2)\n",
        "    x2 = self.relu(x2)\n",
        "\n",
        "    x3 = self.convreduce5x5(x)\n",
        "    x3 = self.relu(x3)\n",
        "    x3 = self.conv5x5(x3)\n",
        "    x3 = self.relu(x3)\n",
        "\n",
        "    x4 = self.maxpool(x)\n",
        "    x4 = self.conv1x1_l4(x4)\n",
        "\n",
        "    out = torch.cat((x1,x2,x3,x4), dim = 1)\n",
        "\n",
        "\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "sVpSvKPaFXF-"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception_imp(nn.Module):\n",
        "  def __init__(self, in_channels = 3, num_classes = 1000):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    self.out_channels = {\n",
        "                         '3a':[64,96,128,16,32,32],\n",
        "                         '3b':[128,128,192,32,96,64],\n",
        "                         '4a':[192,96,208,16,48,64],\n",
        "                         '4b':[160,112,224,24,64,64],\n",
        "                         '4c':[128,128,256,24,64,64],\n",
        "                         '4d':[112,144,288,32,64,64],\n",
        "                         '4e':[256,160,320,32,128,128],\n",
        "                         '5a':[256,160,320,32,128,128],\n",
        "                         '5b':[384,192,384,48,128,128]\n",
        "                       }\n",
        "    self.before_modules = BeforeModules(self.in_channels)\n",
        "\n",
        "    self.module3 = self._build_module(192,{key:value for key,value in self.out_channels.items() if '3' in key})\n",
        "\n",
        "\n",
        "    #self.module4 = self._build_module(self.module3[-1].out_channels,{key:value for key,value in self.out_channels.items() if '4' in key},aux_pos = true, num_classes = self.num_classes)\n",
        "    self.Inc_block4a = Inc_Module(in_channels = self.module3[-1].out_channels, out_channels_list = self.out_channels['4a'])\n",
        "    self.Inc_block4b = Inc_Module(in_channels = self.Inc_block4a.out_channels, out_channels_list =  self.out_channels['4b'])\n",
        "    self.aux_classifier4b = Aux_Classifier(in_channels = self.Inc_block4a.out_channels, num_classes = self.num_classes)\n",
        "    self.Inc_block4c = Inc_Module(in_channels = self.Inc_block4b.out_channels,  out_channels_list = self.out_channels['4c'])\n",
        "    self.Inc_block4d = Inc_Module(in_channels = self.Inc_block4c.out_channels,  out_channels_list = self.out_channels['4d'])\n",
        "    self.Inc_block4e = Inc_Module(in_channels = self.Inc_block4d.out_channels,  out_channels_list = self.out_channels['4e'])\n",
        "    self.aux_classifier4e = Aux_Classifier(in_channels = self.Inc_block4d.out_channels, num_classes = self.num_classes)\n",
        "\n",
        "\n",
        "    self.module5= self._build_module(self.Inc_block4e.out_channels,{key:value for key,value in self.out_channels.items() if '5' in key})\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding = 1)\n",
        "\n",
        "    self.avg_pool = nn.AvgPool2d(kernel_size = 7, stride = 1)\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "    self.fc = nn.Linear(in_features = self.module5[-1].out_channels, out_features = self.num_classes)\n",
        "\n",
        "\n",
        "  def _build_module(self, in_channels,module_dict):\n",
        "    module = []\n",
        "    out_channels_list = list(module_dict.values())\n",
        "    for i in range(len(module_dict)):\n",
        "\n",
        "      block = Inc_Module(in_channels, out_channels_list[i])\n",
        "      module.append(block)\n",
        "      in_channels = block.out_channels\n",
        "\n",
        "    return nn.Sequential(*module)\n",
        "\n",
        "  def forward(self,x):\n",
        "    aux_out1 = None\n",
        "    aux_out2 = None\n",
        "\n",
        "    x = self.before_modules(x)\n",
        "    x = self.module3(self.maxpool(x))\n",
        "\n",
        "\n",
        "    x = self.Inc_block4a(self.maxpool(x))\n",
        "    if self.training:\n",
        "      aux_out1 = self.aux_classifier4b(x)\n",
        "    x = self.Inc_block4b(x)\n",
        "    x = self.Inc_block4c(x)\n",
        "    x = self.Inc_block4d(x)\n",
        "    if self.training:\n",
        "      aux_out2 = self.aux_classifier4e(x)\n",
        "    x = self.Inc_block4e(x)\n",
        "\n",
        "\n",
        "    x = self.module5(self.maxpool(x))\n",
        "\n",
        "    x = self.avg_pool(x)\n",
        "    x = self.dropout(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x, aux_out1, aux_out2\n",
        "\n"
      ],
      "metadata": {
        "id": "vlqlcJS5FaW3"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root=\"data\",\n",
        "                                                         train=True,\n",
        "                                                         download=True,\n",
        "                                                         transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root=\"data\",\n",
        "                                                 train=False,\n",
        "                                                 download=True,\n",
        "                                                 transform=transform)"
      ],
      "metadata": {
        "id": "YAJWpN323Zjx"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False)"
      ],
      "metadata": {
        "id": "6bwRVI2U3Zgd"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Inception_imp(in_channels=1, num_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0VYRL180y06",
        "outputId": "ffc936f2-5012-4eb4-8126-e27844839e4c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "Sairammmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(params=model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss(reduction='sum')"
      ],
      "metadata": {
        "id": "QxfA0ky43Zdb"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_epoch(model, criterion, optimizer, train_loader, test_loader, epoch, device):\n",
        "  loss_train, loss_val = 0., 0.\n",
        "  acc_train, acc_val = 0., 0.\n",
        "  ntrain = len(train_loader.dataset)\n",
        "  nval = len(test_loader.dataset)\n",
        "\n",
        "  with tqdm(train_loader, unit='batches') as pbar:\n",
        "    for i, (images, labels) in enumerate(pbar):\n",
        "      pbar.set_description(f\"Epoch {epoch}\")\n",
        "\n",
        "      images, labels = images.to(device), labels.to(device).to(torch.long).view(-1)\n",
        "\n",
        "      # training and back-propagation\n",
        "      optimizer.zero_grad()\n",
        "      out_main, out_aux_1, out_aux_2 = model(images)\n",
        "\n",
        "      main_loss = criterion(out_main, labels)\n",
        "      aux_1_loss = criterion(out_aux_1, labels)\n",
        "      aux_2_loss = criterion(out_aux_2, labels)\n",
        "      loss = main_loss + 0.3*aux_1_loss + 0.3*aux_2_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # calculating accuracy\n",
        "      with torch.no_grad():\n",
        "        probs = F.softmax(out_main, dim=1).cpu()\n",
        "        preds = torch.max(probs, dim=1)[1]\n",
        "        acc_train += (preds == labels.cpu()).sum()\n",
        "        loss_train += loss.item()\n",
        "\n",
        "      # validate\n",
        "      if i%100 == 0 or i == len(train_loader) - 1:\n",
        "        loss_val, acc_val = validate(model, criterion, test_loader, device)\n",
        "\n",
        "      if i < len(train_loader) - 1:\n",
        "        denom = images.shape[0] * (i+1)\n",
        "      else:\n",
        "        denom = ntrain\n",
        "\n",
        "      pbar.set_postfix(train_loss=loss_train/denom, valid_loss=loss_val/nval, train_acc=acc_train/denom, valid_acc=acc_val/nval)\n",
        "\n",
        "  return loss_train/ntrain, loss_val/nval, acc_train/ntrain, acc_val/nval\n",
        "\n",
        "def validate(model, criterion, val_loader, device):\n",
        "  acc_val = 0.\n",
        "  loss_val = 0.\n",
        "  with torch.no_grad():\n",
        "    for val_images, val_labels in val_loader:\n",
        "      val_images = val_images.to(device)\n",
        "      val_labels = val_labels.to(device).to(torch.long).view(-1)\n",
        "\n",
        "      val_output, _, _ = model(val_images)\n",
        "      val_loss = criterion(val_output, val_labels)\n",
        "      loss_val += val_loss.item()\n",
        "\n",
        "      probs = F.softmax(val_output, dim=1).cpu()\n",
        "      preds = torch.max(probs, dim=1)[1]\n",
        "      acc_val += (preds == val_labels.cpu()).sum()\n",
        "\n",
        "  return loss_val, acc_val\n",
        "\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  train_accs = []\n",
        "  val_accs = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train_loss, val_loss, train_acc, val_acc = train_epoch(model, criterion, optimizer, train_loader, val_loader, epoch, device)\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "  return train_losses, val_losses, train_accs, val_accs"
      ],
      "metadata": {
        "id": "Ifqb7z4V1FbE"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "epochs = 2\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs = train(model, criterion, optimizer, train_dataloader, test_dataloader, epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKLGU1Zr1FVN",
        "outputId": "3d28b73c-6c0e-48f1-8db2-f6ad2520f073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   0%|          | 0/938 [00:00<?, ?batches/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRBr7Fb31FRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mG081av1FMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQ1siZqU1FKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kTb5mj5Q1FIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchsummary import summary\n",
        "inc  = torchvision.models.googlenet()\n",
        "summary(inc, (3, 224, 224))"
      ],
      "metadata": {
        "id": "IeQ14o4xYFRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inc"
      ],
      "metadata": {
        "id": "IAke_QAbZlQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8fct0fCr3ZeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}